{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "# import pathlib\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.feature import hog\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_file_path = \"./files/LP_COORDS.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lp_coord(image_name):\n",
    "    image_name = os.path.basename(str(image_name))\n",
    "    lp_coords = np.load(lp_file_path, allow_pickle = True)['coords'].tolist()\n",
    "    (lp_x1, lp_y1, lp_x2, lp_y2) = lp_coords[image_name]\n",
    "    lp_w, lp_h = lp_x2 - lp_x1, lp_y2 - lp_y1\n",
    "    lp_xc = int((lp_x1 + lp_x2)/2)\n",
    "    return (lp_x1, lp_y1, lp_x2, lp_y2), (lp_w, lp_h, lp_xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(input_dir, ext = \"jpg\", shuffle = True):\n",
    "    image_paths = [i for i in pathlib.Path(input_dir).rglob(\"*.jpg\")] #(\".\".join([\"*\", ext]))]\n",
    "    if shuffle:\n",
    "        random.shuffle(image_paths)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_smooth(input_array, win_size = 10):\n",
    "    step = win_size //2 \n",
    "    len_array = len(input_array)\n",
    "    return_array = []\n",
    "    for index, value in enumerate(input_array):\n",
    "        i_range = [ max(0, index - step), min(len_array, index + step)]\n",
    "        return_array.append(np.mean(input_array[i_range[0] : i_range[1] + 1]))\n",
    "    return np.asarray(return_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_split(input_list, ratio = [0.5, 0.5], shuffle = False):\n",
    "    assert sum(ratio) == 1, print(\"sum of ratio should be 1\")\n",
    "    input_list = sorted(input_list)\n",
    "    len_list = len(input_list)\n",
    "    \n",
    "    split_len = []\n",
    "    for i in ratio[:-1]:\n",
    "        split_len.append(round(len_list*i))\n",
    "    \n",
    "    return_list = []\n",
    "    temp = 0\n",
    "    for i in split_len:\n",
    "        start, end = temp, temp + i\n",
    "        temp += i\n",
    "        return_list.append(input_list[start: end])\n",
    "    return_list.append(input_list[temp:])\n",
    "        \n",
    "    return return_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(file_name, is_gray = False, resize = False, width = None, height = None):\n",
    "    if is_gray:\n",
    "        image = cv2.imread(str(file_name), flags = cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        image = cv2.cvtColor(cv2.imread(str(file_name)), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if resize:\n",
    "        h, w = image.shape[:2]\n",
    "        if width == None and height != None:\n",
    "            width = int(height/h*w)\n",
    "        elif width != None and height == None:\n",
    "            height = int(width/w*h)\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "def resize(input_image, is_gray = True, width = None, height = None):\n",
    "    if is_gray and len(input_image.shape) == 3:\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h, w = input_image.shape[:2]\n",
    "    if width == None and height != None:\n",
    "        width = int(height/h*w)\n",
    "    elif width != None and height == None:\n",
    "        height = int(width/w*h)\n",
    "\n",
    "    input_image = cv2.resize(input_image, (width, height))\n",
    "    \n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (256, 128) \n",
    "blockSize = (64, 64)\n",
    "blockStride = (32, 32)\n",
    "cellSize = (32,32)\n",
    "nbins = 9\n",
    "derivAperture = 1\n",
    "winSigma = -1.\n",
    "histogramNormType = 1\n",
    "L2HysThreshold = 0.2\n",
    "gammaCorrection = 1\n",
    "nlevels = 64\n",
    "signedGradients = True\n",
    "\n",
    "# winSize = (256, 128) \n",
    "# blockSize = (32, 32)\n",
    "# blockStride = (16, 16)\n",
    "# cellSize = (16,16)\n",
    "# nbins = 9\n",
    "# derivAperture = 1\n",
    "# winSigma = -1.\n",
    "# histogramNormType = 1\n",
    "# L2HysThreshold = 0.2\n",
    "# gammaCorrection = 1\n",
    "# nlevels = 64\n",
    "# signedGradients = True\n",
    "\n",
    "cvhog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,\n",
    "                        derivAperture,winSigma,histogramNormType,L2HysThreshold,\n",
    "                        gammaCorrection,nlevels,signedGradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG_feature(image, is_gray = True, is_resize = False, width = None,\n",
    "                height = None, ori = 9, ppc = (32,32), cpb = (2,2), block_norm = \"L2-Hys\", ):\n",
    "    \n",
    "    if is_gray and len(image.shape) == 3 :\n",
    "        image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if is_resize:\n",
    "        image = resize(image, is_gray = is_gray, width = width, height = height)\n",
    "    \n",
    "    return hog(image,\n",
    "                orientations = ori, \n",
    "                pixels_per_cell = ppc, \n",
    "                cells_per_block = cpb, \n",
    "                block_norm = block_norm, \n",
    "                visualize=False, \n",
    "                transform_sqrt=False, \n",
    "                feature_vector=True, \n",
    "                multichannel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_extraction_1(input_image):\n",
    "    image_name = os.path.basename(str(input_image))\n",
    "    image = imread(str(input_image))\n",
    "    h, w = image.shape[:2]\n",
    "    (x1, y1, x2, y2), (lp_w, lp_h, _) = get_lp_coord(image_name)\n",
    "    \n",
    "    roi_x1, roi_x2 = max(0, int(x1 - 0.8*lp_w)), min(int(x2 + 0.8*lp_w), w)\n",
    "    roi_y1, roi_y2 = max(0, int(y1 - 0.32*(roi_x2 - roi_x1))), y1\n",
    "    \n",
    "    return [x1, y1, x2, y2], [roi_x1, roi_y1, roi_x2, roi_y2], image[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_extraction_2(input_image):\n",
    "    image_name = os.path.basename(str(input_image))\n",
    "    image = imread(str(input_image))\n",
    "    h, w = image.shape[:2]\n",
    "    (x1, y1, x2, y2), (lp_w, lp_h, _) = get_lp_coord(image_name)\n",
    "    \n",
    "    roi_x1, roi_x2 = max(0, int(x1 - 0.84*lp_w)), min(int(x2 + 0.84*lp_w), w)  \n",
    "    roi_y1, roi_y2 = max(0, int(y1 - 3.67*lp_h)), min(int(y2 + 1.53*lp_h), h)\n",
    "    \n",
    "    return [x1, y1, x2, y2], [roi_x1, roi_y1, roi_x2, roi_y2], image[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_extraction_with_hood(input_image):\n",
    "    \n",
    "    # step 0\n",
    "    image = imread(str(input_image), is_gray = True)\n",
    "    \n",
    "    im_h, im_w = image.shape[:2]\n",
    "    (lp_x1, lp_y1, lp_x2, lp_y2), (lp_w, lp_h, lp_xc) = get_lp_coord(input_image)\n",
    "\n",
    "    # step 1 ： roi 下边界\n",
    "    roi_y2 = lp_y1\n",
    "    \n",
    "    \n",
    "    # step 2 : roi 上边界\n",
    "    # ROI上边界的搜索区域的左右边界 = 从车牌两侧扩展 0.8 倍车牌宽度，\n",
    "    # ROI上边界的搜索区域的上下边界 = 从车牌上方扩展 0.8倍车牌 -- 1.45 倍车牌宽度\n",
    "    sr_x1, sr_x2 = int(max(0, lp_x1 - 1.2*lp_w)), int(min(im_w, lp_x2 + 1.2*lp_w))  # 1.5\n",
    "    sr_y1, sr_y2 = int(max(0, lp_y1 - 1.45*lp_w)), int(max(0, min(im_h, lp_y1 - 0.8*lp_w)))\n",
    "    sr_w,  sr_h = sr_x2 - sr_x1, sr_y2 - sr_y1\n",
    "    \n",
    "    # 当车牌距离图片顶端很近时\n",
    "    if abs(sr_y1 - sr_y2) < 10:\n",
    "        roi_y1 = 0\n",
    "    else:\n",
    "        sr = image[sr_y1:sr_y2, sr_x1:sr_x2]\n",
    "\n",
    "\n",
    "        # blur the image \n",
    "        sr_blur = cv2.GaussianBlur(sr, ksize=(5, 5), sigmaX=0, sigmaY=0)\n",
    "        # sobel y\n",
    "        sobel_sr_y = cv2.convertScaleAbs(cv2.Sobel(sr_blur, cv2.CV_16S, 0, 1, ksize = 3))\n",
    "\n",
    "        # horizontal projection and normalize\n",
    "        # 去除边缘图像左右两侧1/4的梯度信息，这部分信息可能包含车辆以外的梯度噪声，\n",
    "        # 对挡风玻璃下沿的投影效果产生影响\n",
    "        sobel_sr_y[:, :sobel_sr_y.shape[1]//4] = 0\n",
    "        sobel_sr_y[:, sobel_sr_y.shape[1]//4*3:] = 0\n",
    "\n",
    "        y_project = np.sum(sobel_sr_y, 1)\n",
    "        y_project = y_project / np.max(y_project)\n",
    "        y_project = mean_smooth(y_project, win_size = 10)\n",
    "\n",
    "        # the roi_y1\n",
    "        roi_y1 = np.argmax(y_project) + sr_y1\n",
    "    \n",
    "    # step 3 : roi 左右边界\n",
    "    kernel=np.array([[-1,0,1],\n",
    "                          [-1,0,1],\n",
    "                          [-1,0,1],])\n",
    "    \n",
    "#     return [], [], image[sr_y1+ int(0.3*lp_w):roi_y2, sr_x1:sr_x2]\n",
    "    \n",
    "    raw_roi = image[roi_y1 : roi_y2, sr_x1 : sr_x2]\n",
    "\n",
    "    # 如果车牌左边界向左移动1.25个车牌宽度后距离图片边界还有至少20个像素，\n",
    "    # 则左侧的右边界 = 搜索区域左边界 + 0.55个车牌宽度\n",
    "    left_bound = sr_x1 + int(0.55*lp_w) if (lp_x1 - 1.25*lp_w) > 20 else 0\n",
    "    if left_bound == 0:\n",
    "        roi_x1 = 0\n",
    "    else:\n",
    "        left_region = image[roi_y1:lp_y1, sr_x1 : left_bound]\n",
    "    \n",
    "        left_region[:left_region.shape[0]//5,:] = 0\n",
    "        left_region = cv2.GaussianBlur(left_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "\n",
    "        \n",
    "\n",
    "        left_region = np.float32(left_region)\n",
    "        left_region = cv2.filter2D(left_region, -1, kernel)\n",
    "        left_region = cv2.convertScaleAbs(left_region) #\n",
    "        left_region = cv2.threshold(left_region,11,1,cv2.THRESH_OTSU)[1]\n",
    "        left_region = np.uint8(skeletonize(left_region)*255)\n",
    "        left_region = cv2.blur(left_region, (1, 5)) #left_region = cv2.GaussianBlur(left_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "\n",
    "\n",
    "        left_project = np.sum(left_region, 0)\n",
    "        left_project = left_project / np.max(left_project)\n",
    "        left_project = mean_smooth(left_project, win_size = 5)\n",
    "\n",
    "        x_left = np.argmax(left_project) #- 10\n",
    "        roi_x1 = x_left + sr_x1\n",
    "    \n",
    "    \n",
    "    # 如果车牌右边界向右移动1.25个车牌宽度后距离图片还有至少20个像素，\n",
    "    # 则设定右侧边界的左边界 = 搜索区域右边界-0.55个车牌宽度\n",
    "    right_bound = int(sr_x2 - 0.55*lp_w) if (image.shape[1] - (lp_x2 + 1.25*lp_w)) > 20 else raw_roi.shape[1]\n",
    "    if right_bound == raw_roi.shape[1]:\n",
    "        roi_x2 = image.shape[1]\n",
    "    else:\n",
    "        \n",
    "        right_region = image[roi_y1:lp_y1, right_bound: sr_x2]\n",
    "\n",
    "#         print(right_bound, sr_x2)\n",
    "\n",
    "\n",
    "\n",
    "        right_region[:right_region.shape[0]//5,:] = 0\n",
    "        right_region = cv2.GaussianBlur(right_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "\n",
    "        right_region = np.float32(right_region)\n",
    "        right_region = cv2.filter2D(right_region, -1, kernel)\n",
    "        right_region = cv2.convertScaleAbs(right_region) \n",
    "        right_region = cv2.threshold(right_region,11,1,cv2.THRESH_OTSU)[1]\n",
    "        right_region = np.uint8(skeletonize(right_region)*255)\n",
    "        right_region = cv2.blur(right_region, (1, 5))#cv2.GaussianBlur(right_region, ksize=(15, 3), sigmaX=0, sigmaY=0)\n",
    "\n",
    "        right_project = np.sum(right_region, 0)\n",
    "        right_project = right_project /np.max(right_project)\n",
    "        right_project = mean_smooth(right_project, win_size = 5)\n",
    "\n",
    "        x_right = np.argmax(right_project) #+ 10\n",
    "        roi_x2 = x_right + right_bound\n",
    "    \n",
    "    \n",
    "    \n",
    "    dist = min(roi_x2 - lp_xc, lp_xc - roi_x1)\n",
    "    roi_x1, roi_x2 = lp_xc - dist, lp_xc + dist\n",
    "    \n",
    "    return [lp_x1, lp_y1, lp_x2, lp_y2], [roi_x1, roi_y1, roi_x2, roi_y2], image[roi_y1+int(0.3*lp_w):roi_y2, roi_x1:roi_x2]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class roi:\n",
    "    def __init__():\n",
    "        self.image = None\n",
    "    def extract(image_path):\n",
    "        self.image = imread(image_path)\n",
    "        self.im_h, self.im_w = image.shape[:2]\n",
    "        (self.lp_x1, self.lp_y1, self.lp_x2, self.lp_y2), (self.lp_w, self.lp_h, self.lp_xc) = \\\n",
    "            get_lp_coord(image_path)\n",
    "        self.roi_y2 = self.lp_y1\n",
    "        \n",
    "    def hood_search_region():\n",
    "        self.sr_x1, self.sr_x2 = \n",
    "                int(max(0, self.lp_x1 - 1.5*self.lp_w)), int(min(self.im_w, self.lp_x2 + 1.5*self.lp_w))\n",
    "        self.sr_y1, self.sr_y2 = \n",
    "                int(max(0, self.lp_y1 - 1.45*self.lp_w)), int(max(0, min(self.im_h, self.lp_y1 - 0.8*self.lp_w)))\n",
    "        self.sr_w,  self.sr_h = self.sr_x2 - self.sr_x1, self.sr_y2 - self.sr_y1\n",
    "        # 当车辆牌照距离图片顶端很近时\n",
    "        if self.sr_y1 == self.sr_y2 ==0:\n",
    "            self.sr_y2 = 1\n",
    "        self.sr = cv2.cvtColor(self.image[self.sr_y1:self.sr_y2, self.sr_x1:self.sr_x2], cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def mean_accuracy(y_true, y_pred):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.asarray(y_true)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    unique_label = np.unique(y_true)\n",
    "    per_class_acc = []\n",
    "    for label in unique_label:\n",
    "        index = np.where(y_true == label)\n",
    "        per_class_acc.append(np.mean(y_true[index] == y_pred[index]))\n",
    "    return np.mean(per_class_acc, dtype=np.float32)\n",
    "\n",
    "\n",
    "def mean_prec(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average = \"macro\")\n",
    "\n",
    "def overall_prec(y_true, y_pred):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.asarray(y_true)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    return np.mean(y_true == y_pred, dtype=np.float32)\n",
    "\n",
    "\n",
    "def mean_recall(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average = \"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
