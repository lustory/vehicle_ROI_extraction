{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "# import pathlib\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.feature import hog\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp_file_path = \"/media/D/lulei/vehicle_ROI_extraction/files/LP_COORDS.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lp_coord(image_name):\n",
    "    image_name = os.path.basename(str(image_name))\n",
    "    lp_coords = np.load(lp_file_path, allow_pickle = True)['coords'].tolist()\n",
    "    (lp_x1, lp_y1, lp_x2, lp_y2) = lp_coords[image_name]\n",
    "    lp_w, lp_h = lp_x2 - lp_x1, lp_y2 - lp_y1\n",
    "    lp_xc = int((lp_x1 + lp_x2)/2)\n",
    "    return (lp_x1, lp_y1, lp_x2, lp_y2), (lp_w, lp_h, lp_xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_images(input_dir, ext = \"jpg\", shuffle = True):\n",
    "    image_paths = [i for i in pathlib.Path(input_dir).rglob(\"*.jpg\")] #(\".\".join([\"*\", ext]))]\n",
    "    if shuffle:\n",
    "        random.shuffle(image_paths)\n",
    "    return image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_smooth(input_array, win_size = 10):\n",
    "    step = win_size //2 \n",
    "    len_array = len(input_array)\n",
    "    return_array = []\n",
    "    for index, value in enumerate(input_array):\n",
    "        i_range = [ max(0, index - step), min(len_array, index + step)]\n",
    "        return_array.append(np.mean(input_array[i_range[0] : i_range[1] + 1]))\n",
    "    return np.asarray(return_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_split(input_list, ratio = [0.5, 0.5], shuffle = False):\n",
    "    assert sum(ratio) == 1, print(\"sum of ratio should be 1\")\n",
    "    input_list = sorted(input_list)\n",
    "    len_list = len(input_list)\n",
    "    \n",
    "    split_len = []\n",
    "    for i in ratio[:-1]:\n",
    "        split_len.append(round(len_list*i))\n",
    "    \n",
    "    return_list = []\n",
    "    temp = 0\n",
    "    for i in split_len:\n",
    "        start, end = temp, temp + i\n",
    "        temp += i\n",
    "        return_list.append(input_list[start: end])\n",
    "    return_list.append(input_list[temp:])\n",
    "        \n",
    "    return return_list\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imread(file_name, is_gray = False, resize = False, width = None, height = None):\n",
    "    if is_gray:\n",
    "        image = cv2.imread(str(file_name), flags = cv2.IMREAD_GRAYSCALE)\n",
    "    else:\n",
    "        image = cv2.cvtColor(cv2.imread(str(file_name)), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    if resize:\n",
    "        h, w = image.shape[:2]\n",
    "        if width == None and height != None:\n",
    "            width = int(height/h*w)\n",
    "        elif width != None and height == None:\n",
    "            height = int(width/w*h)\n",
    "\n",
    "        image = cv2.resize(image, (width, height))\n",
    "        \n",
    "    return image\n",
    "\n",
    "\n",
    "def resize(input_image, is_gray = True, width = None, height = None):\n",
    "    if is_gray and len(input_image.shape) == 3:\n",
    "        input_image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    h, w = input_image.shape[:2]\n",
    "    if width == None and height != None:\n",
    "        width = int(height/h*w)\n",
    "    elif width != None and height == None:\n",
    "        height = int(width/w*h)\n",
    "\n",
    "    input_image = cv2.resize(input_image, (width, height))\n",
    "    \n",
    "    return input_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "winSize = (256, 128) \n",
    "blockSize = (64, 64)\n",
    "blockStride = (32, 32)\n",
    "cellSize = (32,32)\n",
    "nbins = 9\n",
    "derivAperture = 1\n",
    "winSigma = -1.\n",
    "histogramNormType = 1\n",
    "L2HysThreshold = 0.2\n",
    "gammaCorrection = 1\n",
    "nlevels = 64\n",
    "signedGradients = True\n",
    "\n",
    "# winSize = (256, 128) \n",
    "# blockSize = (32, 32)\n",
    "# blockStride = (16, 16)\n",
    "# cellSize = (16,16)\n",
    "# nbins = 9\n",
    "# derivAperture = 1\n",
    "# winSigma = -1.\n",
    "# histogramNormType = 1\n",
    "# L2HysThreshold = 0.2\n",
    "# gammaCorrection = 1\n",
    "# nlevels = 64\n",
    "# signedGradients = True\n",
    "\n",
    "cvhog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins,\n",
    "                        derivAperture,winSigma,histogramNormType,L2HysThreshold,\n",
    "                        gammaCorrection,nlevels,signedGradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG_feature(image, is_gray = True, is_resize = False, width = None,\n",
    "                height = None, ori = 9, ppc = (32,32), cpb = (2,2), block_norm = \"L2-Hys\", ):\n",
    "    \n",
    "    if is_gray and len(image.shape) == 3 :\n",
    "        image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if is_resize:\n",
    "        image = resize(image, is_gray = is_gray, width = width, height = height)\n",
    "    \n",
    "    return hog(image,\n",
    "                orientations = ori, \n",
    "                pixels_per_cell = ppc, \n",
    "                cells_per_block = cpb, \n",
    "                block_norm = block_norm, \n",
    "                visualize=False, \n",
    "                transform_sqrt=False, \n",
    "                feature_vector=True, \n",
    "                multichannel=None)\n",
    "\n",
    "\n",
    "def HOG_feature_2(image, is_gray = True, is_resize = False, width = None,\n",
    "                height = None, ori = 9, ppc = (25,25), cpb = (2,2), block_norm = \"L2\", ):\n",
    "    \n",
    "    if is_gray and len(image.shape) == 3 :\n",
    "        image = cv2.cvtColor(input_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if is_resize:\n",
    "        image = resize(image, is_gray = is_gray, width = width, height = height)\n",
    "    \n",
    "    return hog(image,\n",
    "                orientations = ori, \n",
    "                pixels_per_cell = ppc, \n",
    "                cells_per_block = cpb, \n",
    "                block_norm = block_norm, \n",
    "                visualize=False, \n",
    "                transform_sqrt=False, \n",
    "                feature_vector=True, \n",
    "                multichannel=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_extraction_1(input_image):\n",
    "    image_name = os.path.basename(str(input_image))\n",
    "    image = imread(str(input_image))\n",
    "    h, w = image.shape[:2]\n",
    "    (x1, y1, x2, y2), (lp_w, lp_h, _) = get_lp_coord(image_name)\n",
    "    \n",
    "    roi_x1, roi_x2 = max(0, int(x1 - 0.8*lp_w)), min(int(x2 + 0.8*lp_w), w)\n",
    "    roi_y1, roi_y2 = max(0, int(y1 - 0.32*(roi_x2 - roi_x1))), y1\n",
    "    \n",
    "    return [x1, y1, x2, y2], [roi_x1, roi_y1, roi_x2, roi_y2], image[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_extraction_2(input_image):\n",
    "    image_name = os.path.basename(str(input_image))\n",
    "    image = imread(str(input_image))\n",
    "    h, w = image.shape[:2]\n",
    "    (x1, y1, x2, y2), (lp_w, lp_h, _) = get_lp_coord(image_name)\n",
    "    \n",
    "    roi_x1, roi_x2 = max(0, int(x1 - 0.84*lp_w)), min(int(x2 + 0.84*lp_w), w)  \n",
    "    roi_y1, roi_y2 = max(0, int(y1 - 3.67*lp_h)), min(int(y2 + 1.53*lp_h), h)\n",
    "    \n",
    "    return [x1, y1, x2, y2], [roi_x1, roi_y1, roi_x2, roi_y2], image[roi_y1:roi_y2, roi_x1:roi_x2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class roi_extraction:\n",
    "    def __init__(self,input_image):\n",
    "        # 输入灰度图片\n",
    "        self.image = imread(str(input_image), is_gray = True)\n",
    "        self.image_copy = self.image.copy()\n",
    "        # 输入图片的宽度和高度\n",
    "        self.im_h, self.im_w = self.image.shape[:2]\n",
    "        # 车牌相关参数\n",
    "        (self.lp_x1, self.lp_y1, self.lp_x2, self.lp_y2), (self.lp_w, self.lp_h, self.lp_xc) = get_lp_coord(input_image)\n",
    "        # roi区域的四个边界值\n",
    "        self.roi_x1, self.roi_x2, self.roi_y1, self.roi_y2 = 0, 0, 0, 0 \n",
    "        # roi下边沿等于车牌上边沿\n",
    "        self.roi_y2 = self.lp_y1\n",
    "        # 左右边界用于求取梯度的kernel\n",
    "        self.kernel=np.array([[-1,0,1],\n",
    "                              [-1,0,1],\n",
    "                              [-1,0,1],])\n",
    "          \n",
    "    def up_down(self):\n",
    "        \n",
    "        # roi上边界搜索区域的提取\n",
    "        \n",
    "        # 候选区域左右边界延展的参数\n",
    "        alpha = 1.2\n",
    "        # 候选区域上下边界延展的参数\n",
    "        beta = 1\n",
    "        gamma = 0.8\n",
    "        \n",
    "        sr_x1, sr_x2 = int(max(0, self.lp_x1 - alpha*self.lp_w)), int(min(self.im_w, self.lp_x2 + alpha*self.lp_w))  # 1.5\n",
    "        sr_y1, sr_y2 = int(max(0, self.lp_y1 - beta*self.lp_w)), int(max(0, min(self.im_h, self.lp_y1 - gamma*self.lp_w)))\n",
    "        sr_w,  sr_h = sr_x2 - sr_x1, sr_y2 - sr_y1\n",
    "\n",
    "        # 当搜索区域的高度小于30时，roi的上边界等于搜索区域的下边界。\n",
    "        if sr_y2 - sr_y1 < 30:\n",
    "            self.roi_y1 = sr_y2\n",
    "        else:\n",
    "            sr = self.image[sr_y1:sr_y2, sr_x1:sr_x2]\n",
    "\n",
    "            # blur the image \n",
    "            sr_blur = cv2.GaussianBlur(sr, ksize=(5, 5), sigmaX=0, sigmaY=0)\n",
    "            # sobel y\n",
    "            sobel_sr_y = cv2.convertScaleAbs(cv2.Sobel(sr_blur, cv2.CV_16S, 0, 1, ksize = 3))\n",
    "\n",
    "            # horizontal projection and normalize\n",
    "            # 去除边缘图像左右两侧1/4的梯度信息，这部分信息可能包含车辆以外的梯度噪声，\n",
    "            # 对挡风玻璃下沿的投影效果产生影响\n",
    "            sobel_sr_y[:, :sobel_sr_y.shape[1]//4] = 0\n",
    "            sobel_sr_y[:, sobel_sr_y.shape[1]//4*3:] = 0\n",
    "\n",
    "            y_project = np.sum(sobel_sr_y, 1)\n",
    "            y_project = y_project / np.max(y_project)\n",
    "            y_project = mean_smooth(y_project, win_size = 10)\n",
    "\n",
    "            # the roi_y1\n",
    "            self.roi_y1 = np.argmax(y_project) + sr_y1 + 10\n",
    "    \n",
    "    \n",
    "    def left_right(self):\n",
    "        \n",
    "        # 搜索区域的左右边界\n",
    "        alpha = 1.2\n",
    "        x1, x2 = int(max(0, self.lp_x1 - alpha*self.lp_w)), int(min(self.im_w, self.lp_x2 + alpha*self.lp_w)) \n",
    "        raw_roi = self.image[self.roi_y1 : self.roi_y2, x1 : x2]\n",
    "        \n",
    "        #     |       |           |           |        |               |         |      |\n",
    "        # 图片边界     x1     left_bound      lp_x1     lp_x2     right_bound    x2   图片边界\n",
    "        # 内侧边界距离车牌边界的最小距离\n",
    "        beta = 0.9\n",
    "        left_bound = int(self.lp_x1 - beta*self.lp_w) if int(self.lp_x1 - beta*self.lp_w) > 0  else 0\n",
    "        ## 如果搜索区域的宽度小于10，则选择内侧作为车辆边界\n",
    "        if left_bound - x1 < 10:\n",
    "            roi_x1 = x1\n",
    "        else:\n",
    "            left_region = self.image[self.roi_y1:self.roi_y2, x1:left_bound]\n",
    "            left_region[:left_region.shape[0]//5,:] = 0\n",
    "            left_region = cv2.GaussianBlur(left_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "\n",
    "            left_region = np.float32(left_region)\n",
    "            left_region = cv2.filter2D(left_region, -1, self.kernel)\n",
    "            left_region = cv2.convertScaleAbs(left_region) #\n",
    "            left_region = cv2.threshold(left_region,11,1,cv2.THRESH_OTSU)[1]\n",
    "            left_region = np.uint8(skeletonize(left_region)*255)\n",
    "            left_region = cv2.blur(left_region, (1, 5)) #left_region = cv2.GaussianBlur(left_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "\n",
    "\n",
    "            left_project = np.sum(left_region, 0)\n",
    "            left_project = left_project / np.max(left_project)\n",
    "            left_project = mean_smooth(left_project, win_size = 5)\n",
    "\n",
    "            x_left = np.argmax(left_project) #- 10\n",
    "            self.roi_x1 = x_left + x1\n",
    "\n",
    "\n",
    "        right_bound = int(self.lp_x2 + beta*self.lp_w) if (self.im_w - self.lp_x2 + beta*self.lp_w) >0 else 0\n",
    "        ## 如果搜索区域的宽度小于10，则选择内侧作为车辆边界\n",
    "        if  x2 - right_bound < 10 :\n",
    "            self.roi_x2 = x2\n",
    "        else:\n",
    "            \n",
    "#             print(self.roi_y1, self.roi_y2, right_bound,x2)\n",
    "            \n",
    "        \n",
    "            right_region = self.image[self.roi_y1:self.roi_y2, right_bound: x2]\n",
    "            right_region[:right_region.shape[0]//5,:] = 0\n",
    "            right_region = cv2.GaussianBlur(right_region, ksize=(15, 15), sigmaX=0, sigmaY=0)\n",
    "            right_region = np.float32(right_region)\n",
    "            right_region = cv2.filter2D(right_region, -1, self.kernel)\n",
    "            right_region = cv2.convertScaleAbs(right_region) \n",
    "            right_region = cv2.threshold(right_region,11,1,cv2.THRESH_OTSU)[1]\n",
    "            right_region = np.uint8(skeletonize(right_region)*255)\n",
    "            right_region = cv2.blur(right_region, (1, 5))#cv2.GaussianBlur(right_region, ksize=(15, 3), sigmaX=0, sigmaY=0)\n",
    "\n",
    "            right_project = np.sum(right_region, 0)\n",
    "            right_project = right_project /np.max(right_project)\n",
    "            right_project = mean_smooth(right_project, win_size = 5)\n",
    "\n",
    "            x_right = np.argmax(right_project) #+ 10\n",
    "            self.roi_x2 = x_right + right_bound\n",
    "\n",
    "        \n",
    "\n",
    "        dist = min(self.roi_x2 - self.lp_xc, self.lp_xc - self.roi_x1)\n",
    "        self.roi_x1, self.roi_x2 = self.lp_xc - dist, self.lp_xc + dist\n",
    "        \n",
    "        \n",
    "    def compute(self):\n",
    "        self.up_down()\n",
    "        self.left_right()\n",
    "        return [self.lp_x1, self.lp_y1, self.lp_x2, self.lp_y2], \\\n",
    "                [self.roi_x1, self.roi_y1, self.roi_x2, self.roi_y2], \\\n",
    "                    self.image_copy[self.roi_y1:self.roi_y2, self.roi_x1:self.roi_x2]\n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "class roi:\n",
    "    def __init__():\n",
    "        self.image = None\n",
    "    def extract(image_path):\n",
    "        self.image = imread(image_path)\n",
    "        self.im_h, self.im_w = image.shape[:2]\n",
    "        (self.lp_x1, self.lp_y1, self.lp_x2, self.lp_y2), (self.lp_w, self.lp_h, self.lp_xc) = \\\n",
    "            get_lp_coord(image_path)\n",
    "        self.roi_y2 = self.lp_y1\n",
    "        \n",
    "    def hood_search_region():\n",
    "        self.sr_x1, self.sr_x2 = \n",
    "                int(max(0, self.lp_x1 - 1.5*self.lp_w)), int(min(self.im_w, self.lp_x2 + 1.5*self.lp_w))\n",
    "        self.sr_y1, self.sr_y2 = \n",
    "                int(max(0, self.lp_y1 - 1.45*self.lp_w)), int(max(0, min(self.im_h, self.lp_y1 - 0.8*self.lp_w)))\n",
    "        self.sr_w,  self.sr_h = self.sr_x2 - self.sr_x1, self.sr_y2 - self.sr_y1\n",
    "        # 当车辆牌照距离图片顶端很近时\n",
    "        if self.sr_y1 == self.sr_y2 ==0:\n",
    "            self.sr_y2 = 1\n",
    "        self.sr = cv2.cvtColor(self.image[self.sr_y1:self.sr_y2, self.sr_x1:self.sr_x2], cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true, y_pred)\n",
    "\n",
    "def mean_accuracy(y_true, y_pred):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.asarray(y_true)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    unique_label = np.unique(y_true)\n",
    "    per_class_acc = []\n",
    "    for label in unique_label:\n",
    "        index = np.where(y_true == label)\n",
    "        per_class_acc.append(np.mean(y_true[index] == y_pred[index]))\n",
    "    return np.mean(per_class_acc, dtype=np.float32)\n",
    "\n",
    "\n",
    "def mean_prec(y_true, y_pred):\n",
    "    return precision_score(y_true, y_pred, average = \"macro\")\n",
    "\n",
    "def overall_prec(y_true, y_pred):\n",
    "    if not isinstance(y_true, np.ndarray):\n",
    "        y_true = np.asarray(y_true)\n",
    "    if not isinstance(y_pred, np.ndarray):\n",
    "        y_pred = np.asarray(y_pred)\n",
    "\n",
    "    return np.mean(y_true == y_pred, dtype=np.float32)\n",
    "\n",
    "\n",
    "def mean_recall(y_true, y_pred):\n",
    "    return recall_score(y_true, y_pred, average = \"macro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
